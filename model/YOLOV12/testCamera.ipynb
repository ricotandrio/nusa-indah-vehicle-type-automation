{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Xj_tNzn2PIF"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"ROBOFLOW_API_KEY\"] = \"Uj5MjQA12mDv8vICzSaL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OkVm_QA42dW_",
    "outputId": "11f5385f-96b4-4345-9275-7fb66b4a03cf"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "HOME = os.getcwd()\n",
    "print(HOME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rgor1dVS2iAV",
    "outputId": "f822a304-0b64-40e5-d088-185afb12eab1"
   },
   "outputs": [],
   "source": [
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key = \"Uj5MjQA12mDv8vICzSaL\")\n",
    "project = rf.workspace(\"riz-yak11\").project(\"ultimate-sykrp\")\n",
    "version = project.version(1)\n",
    "dataset = version.download(\"yolov12\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "knY_Lu0H2kpl",
    "outputId": "577e27fc-9ac0-400a-e31e-d6bb187db666"
   },
   "outputs": [],
   "source": [
    "!ls {dataset.location}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MeDJWekY2m1Q"
   },
   "outputs": [],
   "source": [
    "!sed -i '$d' {dataset.location}/data.yaml\n",
    "!sed -i '$d' {dataset.location}/data.yaml\n",
    "!sed -i '$d' {dataset.location}/data.yaml\n",
    "!sed -i '$d' {dataset.location}/data.yaml\n",
    "!echo -e \"test: ../test/images\\ntrain: ../train/images\\nval: ../valid/images\" >> {dataset.location}/data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CwIlJ3P82pXr",
    "outputId": "9060234c-aed9-4f04-f190-69a98b8b4341"
   },
   "outputs": [],
   "source": [
    "!cat {dataset.location}/data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v8AdIsfC21Xr",
    "outputId": "677d23d9-e072-44a3-e957-edc6adb4aeb7"
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import supervision as sv\n",
    "\n",
    "model = YOLO(f'yolov12nultimatekaggle.pt')\n",
    "\n",
    "# First, let's fix the data.yaml file\n",
    "import yaml\n",
    "\n",
    "# Read and fix the data.yaml file properly\n",
    "data_yaml_path = f\"{dataset.location}/data.yaml\"\n",
    "\n",
    "# Create a properly formatted data.yaml file\n",
    "data_content = {\n",
    "    'nc': 2,  # number of classes\n",
    "    'names': ['0', '1'],  # class names\n",
    "    'test': '../test/images',\n",
    "    'train': '../train/images', \n",
    "    'val': '../valid/images'\n",
    "}\n",
    "\n",
    "# Write the corrected data.yaml\n",
    "with open(data_yaml_path, 'w') as file:\n",
    "    yaml.dump(data_content, file, default_flow_style=False)\n",
    "\n",
    "# Now create the dataset\n",
    "ds = sv.DetectionDataset.from_yolo(\n",
    "    images_directory_path = f\"{dataset.location}/test/images\",\n",
    "    annotations_directory_path = f\"{dataset.location}/test/labels\",\n",
    "    data_yaml_path = f\"{dataset.location}/data.yaml\"\n",
    ")\n",
    "\n",
    "ds.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 961
    },
    "id": "sWAZCgMj27mL",
    "outputId": "7c814d3d-2b76-48b9-edb1-0a07c142e6a8"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "i = random.randint(0, len(ds))\n",
    "\n",
    "images_path, image, labels = ds[i]\n",
    "\n",
    "results = model(image, verbose = False)[0]\n",
    "detections = sv.Detections.from_ultralytics(results).with_nms()\n",
    "\n",
    "box_annotator = sv.BoxAnnotator()\n",
    "label_annotator = sv.LabelAnnotator()\n",
    "\n",
    "annotated_image = image.copy()\n",
    "annotated_image = box_annotator.annotate(scene=annotated_image, detections=detections)\n",
    "annotated_image = label_annotator.annotate(scene=annotated_image, detections=detections)\n",
    "\n",
    "sv.plot_image(annotated_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 560
    },
    "id": "BT_6OQ6y4DCf",
    "outputId": "1c18e659-0015-455e-b7fc-c10966b9596c"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import supervision as sv\n",
    "from ultralytics import YOLO\n",
    "\n",
    "image_path = f\"nobas.jpg\"\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "model = YOLO(f'yolov12nultimatekaggle.pt')\n",
    "\n",
    "results = model(image, verbose=False)[0]\n",
    "detections = sv.Detections.from_ultralytics(results)\n",
    "\n",
    "box_annotator = sv.BoxAnnotator()\n",
    "label_annotator = sv.LabelAnnotator()\n",
    "\n",
    "annotated_image = image.copy()\n",
    "annotated_image = box_annotator.annotate(scene=annotated_image, detections=detections)\n",
    "annotated_image = label_annotator.annotate(scene=annotated_image, detections=detections)\n",
    "\n",
    "sv.plot_image(annotated_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "27a8Wlxo4Eag"
   },
   "outputs": [],
   "source": [
    "from supervision.metrics import MeanAveragePrecision\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(f'yolov12nultimatekaggle.pt')\n",
    "\n",
    "predictions = []\n",
    "targets = []\n",
    "\n",
    "for _, image, target in ds:\n",
    "    results = model(image, verbose = False)[0]\n",
    "    detections = sv.Detections.from_ultralytics(results)\n",
    "\n",
    "    predictions.append(detections)\n",
    "    targets.append(target)\n",
    "\n",
    "map = MeanAveragePrecision().update(predictions, targets).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pfrfm5dp4IPn",
    "outputId": "47abbce5-cb8f-4235-d290-36dab9fee188"
   },
   "outputs": [],
   "source": [
    "print(\"mAP 50:95 :\", map.map50_95)\n",
    "print(\"mAP 50 :\", map.map50)\n",
    "print(\"mAP 75 :\", map.map75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 274
    },
    "id": "i_D029IE4I4q",
    "outputId": "badb1c2e-996a-456d-f836-924eefd6fbbe"
   },
   "outputs": [],
   "source": [
    "map.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import supervision as sv\n",
    "# from ultralytics import YOLO\n",
    "\n",
    "# model = YOLO('yolov12nultimatekaggle.pt')\n",
    "\n",
    "# cap = cv2.VideoCapture(0)\n",
    "\n",
    "# if not cap.isOpened():\n",
    "#     raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "# box_annotator = sv.BoxAnnotator()\n",
    "# label_annotator = sv.LabelAnnotator()\n",
    "\n",
    "# while True:\n",
    "#     ret, frame = cap.read()\n",
    "\n",
    "#     if not ret:\n",
    "#         break\n",
    "\n",
    "#     results = model(frame, verbose=False)[0]\n",
    "#     detections = sv.Detections.from_ultralytics(results)\n",
    "\n",
    "#     # Check for \"no-bus\" detections and print \"1\"\n",
    "#     for class_id in detections.class_id:\n",
    "#         if ds.classes[class_id] == \"1\":  # assuming \"1\" is the \"no-bus\" class\n",
    "#             print(\"1\")\n",
    "\n",
    "#     annotated_frame = frame.copy()\n",
    "#     annotated_frame = box_annotator.annotate(scene=annotated_frame, detections=detections)\n",
    "#     annotated_frame = label_annotator.annotate(scene=annotated_frame, detections=detections)\n",
    "\n",
    "#     cv2.imshow('Real-time Detection', annotated_frame)\n",
    "\n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "# # Release the webcam and close the window\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import supervision as sv\n",
    "# from ultralytics import YOLO\n",
    "\n",
    "# model = YOLO('yolov12nultimatekaggle.pt')\n",
    "\n",
    "# cap = cv2.VideoCapture(0)\n",
    "\n",
    "# if not cap.isOpened():\n",
    "#     raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "# box_annotator = sv.BoxAnnotator()\n",
    "# label_annotator = sv.LabelAnnotator()\n",
    "\n",
    "# while True:\n",
    "#     ret, frame = cap.read()\n",
    "\n",
    "#     if not ret:\n",
    "#         break\n",
    "\n",
    "#     results = model(frame, verbose=False)[0]\n",
    "#     detections = sv.Detections.from_ultralytics(results)\n",
    "\n",
    "#     # Check for \"no-bus\" detections and print \"1\"\n",
    "#     for class_id in detections.class_id:\n",
    "#         if ds.classes[class_id] == \"1\":  # assuming \"1\" is the \"no-bus\" class\n",
    "#             print(\"1\")\n",
    "\n",
    "#     annotated_frame = frame.copy()\n",
    "#     annotated_frame = box_annotator.annotate(scene=annotated_frame, detections=detections)\n",
    "#     annotated_frame = label_annotator.annotate(scene=annotated_frame, detections=detections)\n",
    "\n",
    "#     cv2.imshow('Real-time Detection', annotated_frame)\n",
    "\n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "# # Release the webcam and close the window\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import supervision as sv\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolov12nultimatekaggle.pt')\n",
    "\n",
    "# Use video file instead of webcam (0)\n",
    "video_path = \"toll3.mp4\"  # or \"toll2.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    raise IOError(f\"Cannot open video file: {video_path}\")\n",
    "\n",
    "box_annotator = sv.BoxAnnotator()\n",
    "label_annotator = sv.LabelAnnotator()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    results = model(frame, verbose=False)[0]\n",
    "    detections = sv.Detections.from_ultralytics(results)\n",
    "\n",
    "    # Check for \"no-bus\" detections and print \"1\"\n",
    "    for class_id in detections.class_id:\n",
    "        if ds.classes[class_id] == \"1\":  # assuming \"1\" is the \"no-bus\" class\n",
    "            print(\"Sensor nyala\")\n",
    "\n",
    "    annotated_frame = frame.copy()\n",
    "    annotated_frame = box_annotator.annotate(scene=annotated_frame, detections=detections)\n",
    "    annotated_frame = label_annotator.annotate(scene=annotated_frame, detections=detections)\n",
    "\n",
    "    cv2.imshow('Real-time Detection', annotated_frame)\n",
    "\n",
    "    # Optional: Add a small delay to control playback speed\n",
    "    # cv2.waitKey(30) for ~30fps playback\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and close the window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import supervision as sv\n",
    "# from ultralytics import YOLO\n",
    "\n",
    "# model = YOLO('yolov12nultimatekaggle.pt')\n",
    "\n",
    "# # Use video file instead of webcam (0)\n",
    "# video_path = \"toll3.mp4\"  # or \"toll2.mp4\"\n",
    "# cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# if not cap.isOpened():\n",
    "#     raise IOError(f\"Cannot open video file: {video_path}\")\n",
    "\n",
    "# # Get video properties\n",
    "# fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "# width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "# height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# # Define the codec and create VideoWriter object\n",
    "# output_path = \"output_with_detections.mp4\"\n",
    "# fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # You can also use 'XVID'\n",
    "# out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "# box_annotator = sv.BoxAnnotator()\n",
    "# label_annotator = sv.LabelAnnotator()\n",
    "\n",
    "# frame_count = 0\n",
    "# total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# while True:\n",
    "#     ret, frame = cap.read()\n",
    "\n",
    "#     if not ret:\n",
    "#         break\n",
    "\n",
    "#     results = model(frame, verbose=False)[0]\n",
    "#     detections = sv.Detections.from_ultralytics(results)\n",
    "\n",
    "#     # Check for \"no-bus\" detections and print \"1\"\n",
    "#     for class_id in detections.class_id:\n",
    "#         if ds.classes[class_id] == \"1\":  # assuming \"1\" is the \"no-bus\" class\n",
    "#             print(\"Sensor nyala\")\n",
    "\n",
    "#     annotated_frame = frame.copy()\n",
    "#     annotated_frame = box_annotator.annotate(scene=annotated_frame, detections=detections)\n",
    "#     annotated_frame = label_annotator.annotate(scene=annotated_frame, detections=detections)\n",
    "\n",
    "#     # Write the frame to output video\n",
    "#     out.write(annotated_frame)\n",
    "\n",
    "#     # Optional: Display the frame (you can comment this out if you don't want to see it)\n",
    "#     cv2.imshow('Real-time Detection', annotated_frame)\n",
    "\n",
    "#     # Progress tracking\n",
    "#     frame_count += 1\n",
    "#     if frame_count % 30 == 0:  # Print progress every 30 frames\n",
    "#         print(f\"Processed {frame_count}/{total_frames} frames\")\n",
    "\n",
    "#     # Optional: Add a small delay to control playback speed\n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "# # Release everything\n",
    "# cap.release()\n",
    "# out.release()  # Don't forget to release the output video writer\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "# print(f\"Output video saved as: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
